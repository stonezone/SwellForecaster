# üåä SwellForecaster

![North Shore](https://img.shields.io/badge/North%20Shore-Forecast-blue)
![South Shore](https://img.shields.io/badge/South%20Shore-Forecast-orange)
![O'ahu](https://img.shields.io/badge/O'ahu-Hawaii-green)

A sophisticated surf forecasting application for O'ahu that collects marine data from various sources, analyzes it, and generates comprehensive surf forecasts using AI.

## üöÄ Features

- **Multi-source data collection**: Aggregates data from NDBC buoys, ECMWF models, NOAA, and many more sources
- **Advanced swell analysis**: Analyzes North Pacific and Southern Hemisphere conditions affecting Hawaii's shores
- **AI-powered forecasting**: Generates human-readable surf forecasts using GPT-4.1
- **Visual aids**: Creates forecast charts using GPT-Image-1 or DALL-E for easier interpretation
- **Multi-format output**: Produces forecasts in Markdown, HTML, and PDF formats
- **Resilient network handling**: Implements robust error handling with fallbacks for network failures

## üìã Prerequisites

### Core Requirements
- Python ‚â• 3.9
- wgrib2: `brew install wgrib2` (macOS) or `conda install -c conda-forge wgrib2` (Linux)
- grib2json: `brew install grib2json` (macOS) or via conda/manual build (Linux)

| Tool | Why | macOS (Homebrew) | Linux (APT/Conda) |
|------|-----|------------------|-------------------|
| **Python ‚â• 3.9** | runtime | `brew install python` | `sudo apt install python3` |
| **wgrib2** | extracts GRIB slices | `brew install wgrib2` | `conda install -c conda‚Äëforge wgrib2` |
| **grib2json** | GRIB ‚Üí JSON | `brew install grib2json` | manual build |

> Note: If Homebrew can't find `wgrib2`, run `brew update` first or use the conda line.

## üõ†Ô∏è Installation

1. Clone the repository:
   ```bash
   git clone https://github.com/yourusername/SwellForecaster.git
   cd SwellForecaster
   ```

2. Create and activate a virtual environment:
   ```bash
   python -m venv .venv && source .venv/bin/activate
   ```

3. Install required Python packages:
   ```bash
   pip install -r requirements.txt
   ```

4. Install additional dependencies identified during analysis:
   ```bash
   pip install numpy scipy markdown weasyprint beautifulsoup4
   ```

5. Set up your configuration:
   ```bash
   cp config.example.ini config.ini
   ```

6. Edit `config.ini` with your API keys:
   - OPENAI_KEY (required for GPT-4.1 forecast generation)
   - WINDY_KEY (for Windy Point Forecast API)
   - ANTHROPIC_KEY (optional alternative LLM provider)
   - STORMGLASS_KEY (optional for additional wave data)
   - ECMWF_KEY (for European forecasting model data)

## üß© Architecture

### Data Collection Pipeline
- `collector.py`: Orchestrates all data collection agents, creates timestamped data bundles
- `buoys.py`: Fetches NDBC & CDIP buoy data for both real-time and historical analysis
- `models.py`: Processes WaveWatch III (WW3) and GFS model data (requires wgrib2 + grib2json)
- `opc_wpc_agents.py`: Fetches Ocean Prediction Center & Weather Prediction Center charts
- `stormglass_agent.py`: Fetches data from Stormglass API
- `ecmwf_agent.py`: Fetches European Centre for Medium-Range Weather Forecasts data
- `bom_agent.py`: Fetches data from Australian Bureau of Meteorology

### Analysis and Forecast Generation
- `pacific_forecast_analyzer.py`: Processes collected data and generates human-readable surf forecasts using GPT-4.1
- `north_pacific_analysis.py`: Analyzes North Pacific conditions affecting North Shore swells
- `southern_hemisphere.py`: Analyzes Southern Hemisphere conditions affecting South Shore swells

### Support Modules
- `utils.py`: Shared utilities for logging, configuration, CLI arguments, and timestamp handling
- `dns_resolver.py`: Handles DNS resolution with fallbacks for network reliability

## üîÑ Data Flow

1. `collector.py` fetches data from multiple sources and bundles it into `pacific_data/<run_id>/`
2. Each agent is responsible for fetching a specific type of data (buoys, models, charts, etc.)
3. All data is stored with metadata in a bundle directory with unique ID
4. Raw GRIB2 data is processed using wgrib2 and grib2json to extract readable JSON formatted wave data
5. The new `parse_model_data` function processes WW3 JSON data into a structured format
6. `pacific_forecast_analyzer.py` processes a bundle to create a surf forecast in `forecasts/forecast_<run_id>.md`
7. The forecast is generated by providing the collected and preprocessed data to GPT-4.1 via OpenAI's API
8. Visual forecast charts are created using GPT-Image-1 or DALL-E to illustrate the forecast data tables

## üìä Data Sources

| Source | Type | Description |
|--------|------|-------------|
| NDBC | Buoy data | Real-time wave height, period, and direction from NOAA buoys |
| ECMWF | Wave model | European Centre for Medium-Range Weather Forecasts wave data |
| PacIOOS | Wave model | Pacific Islands Ocean Observing System SWAN model data |
| Open-Meteo | Marine & wind | API providing marine and weather forecasts |
| OPC | Charts | Ocean Prediction Center forecast charts |
| NWS | Forecasts | National Weather Service zone forecasts and alerts |
| NOAA-COOPS | Wind observations | Coastal wind measurements |
| Stormglass | Wave data | Aggregated marine data (requires API key) |

## üîß Usage

### Collecting Data
```bash
python collector.py
```

This will create a new data bundle in `pacific_data/<run_id>/` containing charts, GRIB slices, buoy data, and a metadata.json file.

### Generating a Forecast
```bash
python pacific_forecast_analyzer.py
```

This uses the latest data bundle to generate a forecast.

### Using a Specific Data Bundle
```bash
python pacific_forecast_analyzer.py --bundle-id <bundle_id>
```

### Output Examples
- Markdown: `forecasts/forecast_<timestamp>.md`
- HTML: `forecasts/forecast_<timestamp>.html`
- PDF: `forecasts/forecast_<timestamp>.pdf`

### Scheduling Regular Forecasts

Collect at 05:00 UTC daily and forecast at 05:10:

```bash
# crontab example
0 5 * * *  cd /path/to/repo && /usr/bin/python collector.py
10 5 * * * cd /path/to/repo && /usr/bin/python pacific_forecast_analyzer.py
```

## üìù Configuration

The application is configured through `config.ini`, which includes sections for:

- **API**: API keys for various services
- **GENERAL**: Runtime settings, timeouts, retries
- **SOURCES**: Enable/disable various data sources
- **FORECAST**: Control forecast output format and content
- **SSL_EXCEPTIONS**: Domains where SSL verification should be disabled
- **FALLBACK_SOURCES**: Alternative data sources when primary ones fail

### Prompt Templates

The application uses a flexible prompt template system for customizing AI-generated forecasts. Prompts are stored in `prompts.json` and organized by category:

- **forecast.intro**: The main instruction for the AI forecaster
- **forecast.emphasis**: Configurable emphasis on North/South shore conditions
- **forecast.structure**: Detailed formatting instructions for different forecast sections
- **forecast.specialized**: Domain-specific analysis templates (North Pacific, Southern Hemisphere)
- **chart_generation**: Templates for visual chart generation

Example: Modifying the forecast introduction
```json
"intro": "You are a veteran Hawaiian surf forecaster with over 30 years of experience analyzing Pacific storm systems and delivering detailed, educational surf forecasts for Hawaii.\n\nUse your deep expertise in swell mechanics, Pacific climatology, and historical analogs to analyze the following marine data (surf, wind, swell) collected {timestamp} and generate a 10-day surf forecast for O ªahu."
```

Variables like `{timestamp}` are replaced at runtime with actual data. This allows for powerful prompt engineering without changing code.

For detailed documentation on the prompt templating system, see the `docs/prompt_templates.md` and `docs/prompt_example.md` files.

### Forecast Charts

The application can generate visual forecast charts from the tabular data in the forecast:

```ini
[FORECAST]
include_charts = true              # Set to false to disable chart generation
chart_image_size = 1024x1024       # Options: 1024x1024 (square), 1792x1024 (landscape), 1024x1792 (portrait)
chart_image_quality = standard     # Options: standard, hd (hd only works with dall-e-3)
```

Chart generation settings are controlled in `config.ini`:

1. The image model is specified in the `[GENERAL]` section:
   ```ini
   image_model = gpt-image-1      # Default and recommended model
   ```

2. To use DALL-E-3 instead (higher quality but slower):
   ```ini
   image_model = dall-e-3
   chart_image_quality = hd       # Optional HD quality for DALL-E-3
   ```

The generated charts will be included in both the HTML output and in the Markdown file under the appropriate shore section.

## üåê Network Resilience

SwellForecaster is designed with robust error handling:

- Multiple retry logic with exponential backoff
- Alternative DNS resolution for connectivity issues
- Fallback data sources when primary sources fail
- SSL verification exceptions for problematic domains
- Comprehensive logging for all network operations

## üß† AI Integration

The application uses:

- **OpenAI GPT-4.1** for analyzing marine data and generating human-readable forecasts
- **GPT-Image-1** (default) or **DALL-E-3** for creating visual forecast charts
- Flexible prompt templating system through `prompts.json`
- Customizable forecast emphasis (North/South shore) with manual or automatic detection
- Configurable AI parameters (temperature, max tokens, model selection, etc.)

## üì¶ Complete Dependencies

### Core Requirements (in requirements.txt)
- aiohttp - Asynchronous HTTP client for parallel data fetching
- anthropic - Alternative LLM API client
- openai - GPT-4.1 and DALL-E API client
- openai-agents - Enhanced OpenAI agents functionality
- Pillow - Image processing for forecast charts
- python-dateutil - Enhanced date handling
- prometheus-client - Metrics collection
- requests - Synchronous HTTP requests

### Additional Required Packages
- numpy - Numerical operations for swell analysis
- scipy - Scientific computing for wave signal processing
- markdown - Markdown to HTML conversion
- weasyprint - HTML to PDF conversion
- beautifulsoup4 - HTML/XML parsing

### External Tools
- wgrib2 - Processing GRIB2 weather/wave model files
- grib2json - Converting GRIB2 files to JSON for analysis

## üîç Troubleshooting

| Issue | Solution |
|-------|----------|
| `brew install wgrib2` "No formulae" | Run `brew update` first, or use conda: `conda install -c conda-forge wgrib2` |
| HTTP 400 from api.windy.com | Check that your Windy API key is for Point Forecast and is correctly set in config.ini |
| "Error ... Significant_height_of_combined_wind_waves..." | PacIOOS variable names updated - now using "Thgt" for WW3 and "Hsig" for SWAN models |
| Forecast missing images | The analyzer picks top-priority charts; ensure collector saved full-size GIF/PNG, not thumbnails |
| OpenAI API error "invalid model ID" | Ensure you're using a valid model name like "gpt-4.1" in config.ini and no trailing characters |
| PacIOOS image errors | Variable names have been updated for both regular WW3 and SWAN models |
| Want more/less images | Use `--max-images 12` on the analyzer or change `max_images` in config.ini |
| Forecast chart generation fails | Check the image_model setting (default is "gpt-image-1") or try disabling with `include_charts = false` |
| Chart quality or size issues | Adjust chart_image_size and chart_image_quality in the [FORECAST] section |
| Missing South Shore data | Use `--south-swell-emphasis` flag or set `south_swell_emphasis = true` in config.ini |
| ModuleNotFoundError | Ensure all required dependencies are installed, including those not in requirements.txt |
| SSL certificate errors | Check the SSL_EXCEPTIONS section in config.ini for problematic domains |
| Prompts not loading | Verify prompts.json exists and contains valid JSON; check logs for specific errors |

## üìÑ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ü§ù Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add some amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## üôè Acknowledgements

- NOAA/NWS for providing open access to marine data
- ECMWF for wave model data
- PacIOOS for regional wave models
- OpenAI for GPT-4.1 and DALL-E capabilities
- All the data providers that make this project possible# SwellForecaster
# SwellForecaster
# SwellForecaster
# SwellForecaster
